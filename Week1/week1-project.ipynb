{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4b44b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75be9cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPEN_AI_API_KEY\")\n",
    "openai.api_key = api_key\n",
    "\n",
    "if api_key and api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"Api key is working fine\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API KEY.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2af73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb641053",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are given a website with lots of books listed can you pull each book with its category, author and summarize each page with it page number written at the bottom of each page\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9d1cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class website:\n",
    "    book=str\n",
    "    book.title=str\n",
    "    page =str\n",
    "    page_num=int\n",
    "    page.text = str\n",
    "    def __init__(self, url):\n",
    "        self.url\n",
    "        response =requests.get(url)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, \"html.parser\")\n",
    "        self.title= soup.title.string if soup.title else \"No Title Found\"\n",
    "\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\",\"style\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text=\"\"\n",
    "        links = [link.get(\"href\") for link in soup.find_all(\"a\")]\n",
    "        self.links = [link for link in links if link] \n",
    "\n",
    "    def get_book(self):\n",
    "        return f\"Book Title:\\n{self.title}\\nwebpage contents:\\n{self.text}\\n\\n\"\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
