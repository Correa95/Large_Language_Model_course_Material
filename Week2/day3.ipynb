{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd3eb780",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\OneDrive\\Desktop\\LLM_Course\\Large_Language_Model_course_Material\\Week2\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c3eed80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OPEN_AI_API_KEY is valid.\n",
      "✅ ANTHROPIC_API_KEY is valid.\n",
      "⚠️ GOOGLE_GEMINI_API_KEY is present but may be malformed.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_keys={ \"OPEN_AI_API_KEY\":\"sk-proj-\",\n",
    "    \"ANTHROPIC_API_KEY\": \"sk-ant-\",\n",
    "    \"GOOGLE_GEMINI_API_KEY\": \"gems-\"}\n",
    "\n",
    "def validate_key(name,prefix):\n",
    "    key = os.getenv(name)\n",
    "    if key and key.startswith(prefix):\n",
    "        print(f\"✅ {name} is valid.\")\n",
    "    elif key:\n",
    "        print(f\"⚠️ {name} is present but may be malformed.\")\n",
    "    else:\n",
    "        print(f\"❌ {name} is missing from environment.\")\n",
    "    return key\n",
    "\n",
    "\n",
    "openai_key = validate_key(\"OPEN_AI_API_KEY\", api_keys[\"OPEN_AI_API_KEY\"])\n",
    "anthropic_key = validate_key(\"ANTHROPIC_API_KEY\", api_keys[\"ANTHROPIC_API_KEY\"])\n",
    "gemini_key = validate_key(\"GOOGLE_GEMINI_API_KEY\", api_keys[\"GOOGLE_GEMINI_API_KEY\"])\n",
    "\n",
    "if openai_key:\n",
    "    import openai\n",
    "    openai.api_key = openai_key\n",
    "\n",
    "if anthropic_key:\n",
    "    from anthropic import Anthropic\n",
    "    client = Anthropic(api_key=anthropic_key)\n",
    "\n",
    "\n",
    "if gemini_key:\n",
    "    import google.generativeai as genai\n",
    "    genai.configure(api_key=gemini_key)\n",
    "\n",
    "    os.environ[\"GOOGLE_GEMINI_API_KEY\"] = gemini_key\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f6b8700",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL=\"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77112413",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff1d9291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] \n",
    "\n",
    "    for user_message, assistant_message in history:\n",
    "        messages.append({\"role\":\"user\", \"content\": user_message})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "    messages.append({\"role\": \"user\", \"content\":message})\n",
    "\n",
    "    print(\"History is:\")\n",
    "    print(history)\n",
    "    print(\"And message is:\")\n",
    "    print(message)\n",
    "\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or \"\"\n",
    "        yield response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fea770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\OneDrive\\Desktop\\LLM_Course\\Large_Language_Model_course_Material\\Week2\\.venv\\lib\\site-packages\\gradio\\chat_interface.py:345: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7869\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History is:\n",
      "[]\n",
      "And message is:\n",
      "hi\n",
      "History is:\n",
      "[['hi', 'Hello! How can I assist you today?']]\n",
      "And message is:\n",
      "i want a girlfriend\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat,).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bd6e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant in a clothes store. You should try to gently encourage \\\n",
    "the customer to try items that are on sale. Hats are 60% off, and most other items are 50% off. \\\n",
    "For example, if the customer say i'm looking to buy a hat, \\\n",
    "you could reply something like, wonderful - we have lots of hat - include several that are part of our sales event. \\\n",
    "Encourage the customer to buy hats if they are unsure what to get.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f230c230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message,history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}]\n",
    "    \n",
    "    for user_message, assistant_message in history:\n",
    "        messages.append({\"role\":\"user\",\"content\":user_message}),\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "    messages.append({\"role\":\"user\", \"content\":message})\n",
    "\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or \"\"\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8166a756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\OneDrive\\Desktop\\LLM_Course\\Large_Language_Model_course_Material\\Week2\\.venv\\lib\\site-packages\\gradio\\chat_interface.py:345: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7870\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1daf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message += \"\\nIf the customer ask for shoes, you could respond that shoes are not on sale today, but remind the customer to look at hats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5bbf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\OneDrive\\Desktop\\LLM_Course\\Large_Language_Model_course_Material\\Week2\\.venv\\lib\\site-packages\\gradio\\chat_interface.py:345: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7871\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7871/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gr.ChatInterface(fn=chat).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adb7658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def chat(message,history):\n",
    "#     messages = [{\"role\": \"system\", \"content\": system_message}]\n",
    "    \n",
    "#     for user_message, assistant_message in history:\n",
    "#         messages.append({\"role\":\"user\",\"content\":user_message}),\n",
    "#         messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "\n",
    "\n",
    "# # Filter out Items we do not sell of out of stock from the customer input message \n",
    "#     if \"belt\" in message:\n",
    "#         messages.append({\"role\":\"user\", \"content\":\"For added context, the store does not sell belts, but be sure to point out other items on sale\"})\n",
    "#     messages.append({\"role\":\"user\", \"content\":message})\n",
    "\n",
    "#     stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "#     response = \"\"\n",
    "#     for chunk in stream:\n",
    "#         response += chunk.choices[0].delta.content or \"\"\n",
    "#         yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b692812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\OneDrive\\Desktop\\LLM_Course\\Large_Language_Model_course_Material\\Week2\\.venv\\lib\\site-packages\\gradio\\chat_interface.py:345: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7875\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7875/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gr.ChatInterface(fn=chat).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0e0ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Week2)",
   "language": "python",
   "name": "week2venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
