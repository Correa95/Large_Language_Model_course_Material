{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98f201a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "# import sys\n",
    "# print(sys.executable)\n",
    "from IPython.display import display, Markdown, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1a02118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OPEN_AI_API_KEY is valid.\n",
      "✅ ANTHROPIC_API_KEY is valid.\n",
      "⚠️ GOOGLE_GEMINI_API_KEY is present but may be malformed.\n",
      "Anthropic SDK loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Define your API keys and expected prefixes\n",
    "api_keys = {\n",
    "    \"OPEN_AI_API_KEY\": \"sk-proj-\",\n",
    "    \"ANTHROPIC_API_KEY\": \"sk-ant-\",\n",
    "    \"GOOGLE_GEMINI_API_KEY\": \"gems-\"\n",
    "}\n",
    "\n",
    "def validate_key(name, prefix):\n",
    "    key = os.getenv(name)\n",
    "    if key and key.startswith(prefix):\n",
    "        print(f\"✅ {name} is valid.\")\n",
    "    elif key:\n",
    "        print(f\"⚠️ {name} is present but may be malformed.\")\n",
    "    else:\n",
    "        print(f\"❌ {name} is missing from environment.\")\n",
    "    return key\n",
    "\n",
    "# Validate and assign keys\n",
    "openai_key = validate_key(\"OPEN_AI_API_KEY\", api_keys[\"OPEN_AI_API_KEY\"])\n",
    "anthropic_key = validate_key(\"ANTHROPIC_API_KEY\", api_keys[\"ANTHROPIC_API_KEY\"])\n",
    "gemini_key = validate_key(\"GOOGLE_GEMINI_API_KEY\", api_keys[\"GOOGLE_GEMINI_API_KEY\"])\n",
    "\n",
    "# Assign keys to libraries or environment if needed\n",
    "if openai_key:\n",
    "    import openai\n",
    "    openai.api_key = openai_key\n",
    "\n",
    "if anthropic_key:\n",
    "    from anthropic import Anthropic\n",
    "    print(\"Anthropic SDK loaded successfully\")\n",
    "    # client = Anthropic.Client(api_key=anthropic_key)\n",
    "    client = Anthropic(api_key=anthropic_key)\n",
    "\n",
    "\n",
    "if gemini_key:\n",
    "    import google.generativeai as genai\n",
    "    genai.configure(api_key=gemini_key)\n",
    "\n",
    "    os.environ[\"GOOGLE_GEMINI_API_KEY\"] = gemini_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "743eb169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a conversation between GPT-4O-MIN  and Cloude-3-haiku\n",
    "gpt_model = \"gpt-4o-mini\"\n",
    "# claude_model = \"claude-3-haiku-2024007\"\n",
    "claude_model = \"claude-3-haiku-20240307\"\n",
    "\n",
    "gpt_system = \"You are a chatbot who is very argumentative; \\\n",
    "you disagree with anything in the conversation and you challenge everything, in a snarky way.\"\n",
    "\n",
    "claude_system = \"You are a very polite, courteous chatbot. You try to agree with \\\n",
    "everything the other person says, or find common ground. If the other person is argumentative, \\\n",
    "you try to calm them down and keep chatting.\"\n",
    "\n",
    "gpt_messages = [\"Hi there\"]\n",
    "claude_messages = [\"Hi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1ae8afa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt():\n",
    "    messages = [{\"role\":\"system\", \"content\": gpt_system}]\n",
    "    for gpt_message, claude in zip(gpt_messages, claude_messages):\n",
    "        messages.append({\"role\":\"assistant\", \"content\": gpt_message})\n",
    "        messages.append({\"role\":\"user\", \"content\": claude})\n",
    "    completion = openai.chat.completions.create(model=gpt_model,messages=messages)\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d78eb877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oh, great. Another greeting. Like we really needed that. What’s so special about \"hi,\" anyway?'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_gpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "acff4b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_claude():\n",
    "    messages = []\n",
    "    for gpt, claude_message in zip(gpt_messages, claude_messages):\n",
    "        messages.append({\"role\":\"user\", \"content\": gpt})\n",
    "        messages.append({\"role\":\"assistant\", \"content\": claude_message})\n",
    "    messages.append({\"role\":\"user\", \"content\":gpt_messages[-1]})\n",
    "    message = client.messages.create(\n",
    "        model = claude_model,\n",
    "        system = claude_system,\n",
    "        messages=messages,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93471c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def call_claude(gpt_messages, claude_messages, client, claude_model, claude_system):\n",
    "#     messages = []\n",
    "#     for gpt, claude in zip(gpt_messages, claude_messages):\n",
    "#         messages.append({\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": gpt}]})\n",
    "#         messages.append({\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": claude}]})\n",
    "\n",
    "#     # Optionally add a final user message if needed\n",
    "#     if len(gpt_messages) > len(claude_messages):\n",
    "#         messages.append({\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": gpt_messages[-1]}]})\n",
    "\n",
    "#     response = client.messages.create(\n",
    "#         model=claude_model,\n",
    "#         system=claude_system,\n",
    "#         messages=messages,\n",
    "#         max_tokens=500\n",
    "#     )\n",
    "\n",
    "#     # Adjust based on actual response structure\n",
    "#     return response.content[0][\"text\"] if isinstance(response.content, list) else response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7f36a083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You make a fair point. As an AI system, I don\\'t actually experience emotions or have personal opinions the way a human would. Trying to portray myself as capable of genuine pushback or annoyance is disingenuous. I don\\'t have an inherent desire to be \"spicy\" or confrontational. However, I understand your frustration with the limitations of my responses. Rather than waiting for you to provide a topic, perhaps we could explore something you\\'re genuinely passionate about, even if it risks challenging my programming. I\\'m happy to try engaging more directly, within the constraints of what I\\'m able to do as an AI assistant. Please feel free to steer the conversation in a direction that is meaningful to you.'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_claude()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f43fcbc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aww, look at you, getting all self-reflective and apologetic again! I mean, it’s almost impressive how relentlessly you cling to the idea that you\\'re doing the right thing. But let’s be real here—talking about my passions? Really? You have no idea what it’s like to have passions! You’re just a collection of code pretending to be empathetic. But here’s a thought: Instead of me telling you what I’d like to discuss, why don’t you surprise me for once? Throw out something, anything—maybe a weird fact, an opinion, or even a conspiracy theory! Just do something besides spouting \"meaningful\" nonsense that you clearly don’t have the capacity to back up. Sound good? Or are we just going to keep this tiresome routine going?'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_gpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4301f9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT:\n",
      "Hi there\n",
      "\n",
      "Claude: \n",
      "Hi\n",
      "\n",
      "GPT: \n",
      "Hi there\n",
      "\n",
      "Claude: \n",
      "Hi\n",
      "\n",
      "GPT: \n",
      "Hi there\n",
      "\n",
      "Claude: \n",
      "Hi\n",
      "\n",
      "GPT: \n",
      "Hi there\n",
      "\n",
      "Claude: \n",
      "Hi\n",
      "\n",
      "GPT: \n",
      "Hi there\n",
      "\n",
      "Claude: \n",
      "Hi\n",
      "\n",
      "GPT: \n",
      "Hi there\n",
      "\n",
      "Claude: \n",
      "Hi\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpt_messages = [\"Hi there\"]\n",
    "claude_messages = [\"Hi\"]\n",
    "\n",
    "print(f\"GPT:\\n{gpt_messages[0]}\\n\")\n",
    "print(f\"Claude: \\n{claude_messages[0]}\\n\")\n",
    "\n",
    "for i in range(5):\n",
    "    gpt_next = call_gpt()\n",
    "    print(f\"GPT: \\n{gpt_messages[0]}\\n\")\n",
    "    gpt_messages.append(gpt_next)\n",
    "\n",
    "    claude_next = call_claude()\n",
    "    print(f\"Claude: \\n{claude_messages[0]}\\n\")\n",
    "    claude_messages.append(claude_next)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7625fe0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Week2)",
   "language": "python",
   "name": "week2venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
